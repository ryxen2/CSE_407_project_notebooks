{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":15444,"sourceType":"datasetVersion","datasetId":11102},{"sourceId":242592,"sourceType":"datasetVersion","datasetId":102285}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"86f89543-e605-46cd-89a5-41494908f492","cell_type":"markdown","source":"# MobileNetV2 Compression (Kaggle)\n### Real parameter reduction + structured pruning + INT8 quantization (PTQ + QAT)\n- Parameter decrease: `width_mult`\n- Structured pruning: channel pruning with `torch-pruning`\n- Quantization: INT8 PTQ + QAT (CPU / fbgemm)\n\n> If you use your own dataset, replace **CELL 3** only.\n","metadata":{}},{"id":"68c4bbf6-3ec2-42fc-8e00-187f49230fc4","cell_type":"markdown","source":"## CELL 1 — Install (Kaggle)\n","metadata":{}},{"id":"6ba5c6ce-f5ee-42ca-967d-7094009d9d72","cell_type":"code","source":"!pip -q install torchinfo thop pandas torch-pruning\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T17:43:18.756269Z","iopub.execute_input":"2025-12-17T17:43:18.756923Z","iopub.status.idle":"2025-12-17T17:43:23.790214Z","shell.execute_reply.started":"2025-12-17T17:43:18.756863Z","shell.execute_reply":"2025-12-17T17:43:23.789178Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.2/70.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":3},{"id":"ba403cf5-1a73-45bb-a6fa-aa1e5c95a997","cell_type":"markdown","source":"## CELL 2 — Imports + Setup\n","metadata":{}},{"id":"2b71d385-3349-4cd3-ae2c-97846c76c676","cell_type":"code","source":"import os, time, copy, random\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\n\nimport torchvision\nfrom torchvision import datasets, transforms\nfrom torchvision.models import mobilenet_v2\nfrom torchvision.models.quantization import mobilenet_v2 as qmobilenet_v2\n\nfrom thop import profile\nimport torch_pruning as tp\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"DEVICE:\", DEVICE)\n\ndef seed_all(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nseed_all(42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T17:43:45.776465Z","iopub.execute_input":"2025-12-17T17:43:45.777267Z","iopub.status.idle":"2025-12-17T17:43:50.696503Z","shell.execute_reply.started":"2025-12-17T17:43:45.777231Z","shell.execute_reply":"2025-12-17T17:43:50.695801Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"DEVICE: cuda\n","output_type":"stream"}],"execution_count":4},{"id":"a9bef7f9-c948-4b69-a642-1a3981f97afb","cell_type":"markdown","source":"## CELL 3 — Dataset (CIFAR-10 example)\nReplace this cell if you have a custom Kaggle dataset.\n","metadata":{}},{"id":"7894976c-42cb-427c-8d96-83f40761758d","cell_type":"code","source":"BATCH = 128\nNUM_WORKERS = 2\nNUM_CLASSES = 10\n\n# MobileNetV2 = ImageNet normalization + 224 resize\ntrain_tf = transforms.Compose([\n    transforms.Resize(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))\n])\ntest_tf = transforms.Compose([\n    transforms.Resize(224),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))\n])\n\ntrain_ds = datasets.CIFAR10(\"./data\", train=True, download=True, transform=train_tf)\ntest_ds  = datasets.CIFAR10(\"./data\", train=False, download=True, transform=test_tf)\n\ntrain_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\ntest_loader  = DataLoader(test_ds,  batch_size=BATCH, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T17:43:56.126762Z","iopub.execute_input":"2025-12-17T17:43:56.127128Z","iopub.status.idle":"2025-12-17T17:44:02.665199Z","shell.execute_reply.started":"2025-12-17T17:43:56.127098Z","shell.execute_reply":"2025-12-17T17:44:02.664479Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 170M/170M [00:02<00:00, 57.1MB/s] \n","output_type":"stream"}],"execution_count":5},{"id":"0b395c17-8516-4afa-9aa0-fa929f5102f3","cell_type":"markdown","source":"## CELL 4 — Helpers (Acc, Params, Size, Latency, FLOPs)\n","metadata":{}},{"id":"d4010a57-2174-408c-8cee-6325b9bf94ee","cell_type":"code","source":"@torch.no_grad()\ndef evaluate(model, loader, device):\n    model.eval()\n    correct, total = 0, 0\n    for x, y in loader:\n        x, y = x.to(device), y.to(device)\n        out = model(x)\n        pred = out.argmax(1)\n        correct += (pred == y).sum().item()\n        total += y.numel()\n    return correct / total\n\ndef count_params(model):\n    return sum(p.numel() for p in model.parameters())\n\ndef size_mb_fp32(model):\n    return count_params(model) * 4 / (1024**2)\n\n@torch.no_grad()\ndef latency_ms(model, device, input_shape=(1,3,224,224), warmup=30, iters=100):\n    model.eval()\n    x = torch.randn(*input_shape).to(device)\n    for _ in range(warmup):\n        _ = model(x)\n    if device == \"cuda\":\n        torch.cuda.synchronize()\n    t0 = time.time()\n    for _ in range(iters):\n        _ = model(x)\n    if device == \"cuda\":\n        torch.cuda.synchronize()\n    t1 = time.time()\n    return (t1-t0)*1000/iters\n\ndef flops_params(model, device, input_shape=(1,3,224,224)):\n    model.eval()\n    x = torch.randn(*input_shape).to(device)\n    macs, params = profile(model, inputs=(x,), verbose=False)\n    return 2*macs, params\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T17:44:08.260008Z","iopub.execute_input":"2025-12-17T17:44:08.260328Z","iopub.status.idle":"2025-12-17T17:44:08.268782Z","shell.execute_reply.started":"2025-12-17T17:44:08.260301Z","shell.execute_reply":"2025-12-17T17:44:08.268174Z"}},"outputs":[],"execution_count":6},{"id":"5ce7e84d-eb75-4215-96dc-340cb6e54b60","cell_type":"markdown","source":"## CELL 5 — Train / Fine-tune\n","metadata":{}},{"id":"31c6abe7-950a-4fdb-8594-8e836413023a","cell_type":"code","source":"def train_model(model, train_loader, test_loader, epochs=3, lr=1e-4, device=DEVICE):\n    model = model.to(device)\n    opt = optim.Adam(model.parameters(), lr=lr)\n    loss_fn = nn.CrossEntropyLoss()\n\n    best_acc = 0.0\n    best = copy.deepcopy(model.state_dict())\n\n    for ep in range(1, epochs+1):\n        model.train()\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            opt.zero_grad()\n            loss = loss_fn(model(x), y)\n            loss.backward()\n            opt.step()\n\n        acc = evaluate(model, test_loader, device)\n        print(f\"epoch {ep}/{epochs} | acc={acc:.4f}\")\n        if acc > best_acc:\n            best_acc = acc\n            best = copy.deepcopy(model.state_dict())\n\n    model.load_state_dict(best)\n    return model, best_acc\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T17:44:13.887299Z","iopub.execute_input":"2025-12-17T17:44:13.888033Z","iopub.status.idle":"2025-12-17T17:44:13.894438Z","shell.execute_reply.started":"2025-12-17T17:44:13.887999Z","shell.execute_reply":"2025-12-17T17:44:13.893570Z"}},"outputs":[],"execution_count":7},{"id":"f64c64f7-dca7-4a49-8afc-92b1ccbda2a3","cell_type":"markdown","source":"# PART A — Parameter Decrease (width_mult)\n","metadata":{}},{"id":"ad834515-7ba3-4df1-82af-97122d2e824b","cell_type":"markdown","source":"## CELL 6 — Build MobileNetV2 with width_mult\n","metadata":{}},{"id":"32f72cad-d2cd-47d4-bcee-554b4db6fc61","cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nfrom torchvision.models import mobilenet_v2\n\n# Utility to count parameters\ndef count_params(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n# Build MobileNetV2 with safe pretrained loading\ndef build_mobilenet(num_classes=10, width_mult=1.0, pretrained=True):\n    weights = torchvision.models.MobileNet_V2_Weights.DEFAULT if pretrained else None\n    m = mobilenet_v2(weights=None, width_mult=width_mult)  # start with no weights\n    m.classifier[1] = nn.Linear(m.last_channel, num_classes)\n\n    if pretrained:\n        # load only compatible pretrained weights\n        pretrained_model = mobilenet_v2(weights=weights)\n        pretrained_dict = pretrained_model.state_dict()\n        model_dict = m.state_dict()\n        # keep only matching layers\n        pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict and v.size() == model_dict[k].size()}\n        model_dict.update(pretrained_dict)\n        m.load_state_dict(model_dict)\n\n    return m\n\n# Example usage\nNUM_CLASSES = 10\n\nmb_full  = build_mobilenet(NUM_CLASSES, width_mult=1.0, pretrained=True)\nmb_small = build_mobilenet(NUM_CLASSES, width_mult=0.5, pretrained=True)\n\nprint(\"params full :\", count_params(mb_full))\nprint(\"params small:\", count_params(mb_small))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T17:47:53.787755Z","iopub.execute_input":"2025-12-17T17:47:53.788585Z","iopub.status.idle":"2025-12-17T17:47:54.096665Z","shell.execute_reply.started":"2025-12-17T17:47:53.788552Z","shell.execute_reply":"2025-12-17T17:47:54.095955Z"}},"outputs":[{"name":"stdout","text":"params full : 2236682\nparams small: 700490\n","output_type":"stream"}],"execution_count":9},{"id":"c3284f6c-72a1-4416-8580-467c2bfc15c8","cell_type":"markdown","source":"## CELL 7 — Fine-tune baselines\n","metadata":{}},{"id":"55c0532f-bbc0-47d9-ba29-479f4cee7a54","cell_type":"code","source":"mb_full,  acc_full  = train_model(mb_full,  train_loader, test_loader, epochs=3, lr=1e-4)\nmb_small, acc_small = train_model(mb_small, train_loader, test_loader, epochs=3, lr=1e-4)\n\nprint(\"acc_full :\", acc_full)\nprint(\"acc_small:\", acc_small)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T17:49:25.796211Z","iopub.execute_input":"2025-12-17T17:49:25.796572Z","iopub.status.idle":"2025-12-17T17:59:46.675627Z","shell.execute_reply.started":"2025-12-17T17:49:25.796541Z","shell.execute_reply":"2025-12-17T17:59:46.674546Z"}},"outputs":[{"name":"stdout","text":"epoch 1/3 | acc=0.9076\nepoch 2/3 | acc=0.9254\nepoch 3/3 | acc=0.9338\nepoch 1/3 | acc=0.3407\nepoch 2/3 | acc=0.4325\nepoch 3/3 | acc=0.4696\nacc_full : 0.9338\nacc_small: 0.4696\n","output_type":"stream"}],"execution_count":11},{"id":"d0498301-6120-43a8-95ed-04119f6f4946","cell_type":"markdown","source":"# PART B — Structured Pruning \nThis removes channels (not just zeroing weights) so params actually go down.\n","metadata":{}},{"id":"a7661041-5b69-4157-9602-7a0039b0558d","cell_type":"markdown","source":"## CELL 8 — Structured Channel Pruning with torch-pruning\n","metadata":{}},{"id":"34e2985f-33e8-43d5-868d-94012cc21909","cell_type":"code","source":"\ndef structured_prune_mobilenet(model, example_input, prune_ratio=0.30):\n    \"\"\"Real parameter reduction by removing channels.\"\"\"\n    model = copy.deepcopy(model).cpu().eval()\n\n    imp = tp.importance.MagnitudeImportance(p=1)\n\n    ignored_layers = []\n    for m in model.modules():\n        if isinstance(m, nn.Linear) and m.out_features == NUM_CLASSES:\n            ignored_layers.append(m)\n\n    pruner = tp.pruner.MagnitudePruner(\n        model,\n        example_inputs=example_input,\n        importance=imp,\n        pruning_ratio=prune_ratio,\n        ignored_layers=ignored_layers,\n    )\n\n    pruner.step()\n    return model\n\nexample_inp = torch.randn(1,3,224,224)\nmb_struct_pruned = structured_prune_mobilenet(mb_full, example_inp, prune_ratio=0.30).to(DEVICE)\n\nacc_struct = evaluate(mb_struct_pruned, test_loader, DEVICE)\nprint(\"Structured-pruned acc (before finetune):\", acc_struct)\nprint(\"Params after structured prune:\", count_params(mb_struct_pruned))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T17:59:55.287045Z","iopub.execute_input":"2025-12-17T17:59:55.287923Z","iopub.status.idle":"2025-12-17T18:00:08.489440Z","shell.execute_reply.started":"2025-12-17T17:59:55.287884Z","shell.execute_reply":"2025-12-17T18:00:08.488473Z"}},"outputs":[{"name":"stdout","text":"Structured-pruned acc (before finetune): 0.0976\nParams after structured prune: 1116172\n","output_type":"stream"}],"execution_count":12},{"id":"dcd16298-a096-462e-83fb-fa1476a20842","cell_type":"markdown","source":"## CELL 9 — Fine-tune after structured pruning\n","metadata":{}},{"id":"6800c13b-14bb-4667-92d9-fbd47178b46e","cell_type":"code","source":"mb_struct_pruned, acc_struct_ft = train_model(mb_struct_pruned, train_loader, test_loader, epochs=2, lr=5e-5)\nprint(\"Structured-pruned + finetune acc:\", acc_struct_ft)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T18:03:24.706589Z","iopub.execute_input":"2025-12-17T18:03:24.707618Z","iopub.status.idle":"2025-12-17T18:06:37.989992Z","shell.execute_reply.started":"2025-12-17T18:03:24.707575Z","shell.execute_reply":"2025-12-17T18:06:37.988930Z"}},"outputs":[{"name":"stdout","text":"epoch 1/2 | acc=0.7309\nepoch 2/2 | acc=0.7839\nStructured-pruned + finetune acc: 0.7839\n","output_type":"stream"}],"execution_count":13},{"id":"a19a7075-36a1-45fb-9ab7-27b76902ef86","cell_type":"markdown","source":"# PART C — Quantization (INT8) on CPU\n- PTQ = faster, simpler\n- QAT = best INT8 accuracy\n\nNote: INT8 runs on CPU (fbgemm).\n","metadata":{}},{"id":"ac7e9904-28e8-436d-bf73-81ee30a22b7f","cell_type":"markdown","source":"## CELL 10 — Build quant-ready MobileNetV2 and load weights\n","metadata":{}},{"id":"8fafa7d7-a25a-477f-a2e9-bb15911300a9","cell_type":"code","source":"\nimport torch\nimport torch.nn as nn\nimport torch.nn.utils.prune as prune\nimport torch.ao.quantization as tq\nimport torchvision\nfrom torchvision.models import mobilenet_v2, qmobilenet_v2\n\n# ---- 1. Remove pruning masks BEFORE quantization ----\ndef remove_pruning(model):\n    for m in model.modules():\n        if isinstance(m, (nn.Conv2d, nn.Linear)):\n            if hasattr(m, \"weight_orig\"):\n                prune.remove(m, \"weight\")\n    return model\n\nmb_struct_pruned = remove_pruning(mb_struct_pruned).cpu().eval()\n\n# ---- 2. Build quant-ready model with SAME architecture ----\ndef build_quantready_mobilenet(num_classes=10, width_mult=1.0, from_float_model=None):\n    qmodel = qmobilenet_v2(\n        weights=None,\n        quantize=False,\n        width_mult=width_mult\n    )\n    qmodel.classifier[1] = nn.Linear(qmodel.last_channel, num_classes)\n\n    if from_float_model is not None:\n        # architectures MUST match\n        qmodel.load_state_dict(from_float_model.state_dict(), strict=True)\n\n    return qmodel\n\n# ---- 3. Create quant-ready model ----\nmb_qready = build_quantready_mobilenet(\n    NUM_CLASSES,\n    width_mult=1.0,            # MUST match pruned model\n    from_float_model=mb_struct_pruned\n)\n\n# ---- 4. Prepare for quantization ----\nmb_qready.qconfig = tq.get_default_qat_qconfig(\"fbgemm\")\ntq.prepare_qat(mb_qready, inplace=True)\n\nprint(\"✅ Quant-ready model built successfully\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T18:34:10.203563Z","iopub.execute_input":"2025-12-17T18:34:10.203990Z","iopub.status.idle":"2025-12-17T18:34:10.224802Z","shell.execute_reply.started":"2025-12-17T18:34:10.203959Z","shell.execute_reply":"2025-12-17T18:34:10.223775Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/2285775310.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mao\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmobilenet_v2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqmobilenet_v2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# ---- 1. Remove pruning masks BEFORE quantization ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'qmobilenet_v2' from 'torchvision.models' (/usr/local/lib/python3.12/dist-packages/torchvision/models/__init__.py)"],"ename":"ImportError","evalue":"cannot import name 'qmobilenet_v2' from 'torchvision.models' (/usr/local/lib/python3.12/dist-packages/torchvision/models/__init__.py)","output_type":"error"}],"execution_count":15},{"id":"d742f502-8d68-4219-be8d-75568d2a5df7","cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.utils.prune as prune\nimport torch.ao.quantization as tq\nimport torchvision\nfrom torchvision.models import mobilenet_v2\n\n# ---- 1. Remove pruning masks BEFORE quantization ----\ndef remove_pruning(model):\n    for m in model.modules():\n        if isinstance(m, (nn.Conv2d, nn.Linear)):\n            if hasattr(m, \"weight_orig\"):\n                prune.remove(m, \"weight\")\n    return model\n\nmb_struct_pruned = remove_pruning(mb_struct_pruned).cpu().eval()\n\n# ---- 2. Fuse Conv + BN + ReLU (REQUIRED for quantization) ----\ndef fuse_mobilenet(model):\n    for m in model.modules():\n        if isinstance(m, torchvision.models.mobilenetv2.InvertedResidual):\n            if len(m.conv) == 3:\n                tq.fuse_modules(m.conv, [\"0\", \"1\", \"2\"], inplace=True)\n            elif len(m.conv) == 6:\n                tq.fuse_modules(m.conv, [\"0\", \"1\", \"2\"], inplace=True)\n                tq.fuse_modules(m.conv, [\"3\", \"4\", \"5\"], inplace=True)\n    return model\n\nmb_struct_pruned = fuse_mobilenet(mb_struct_pruned)\n\n# ---- 3. Assign Quantization-Aware Training config ----\nmb_struct_pruned.qconfig = tq.get_default_qat_qconfig(\"fbgemm\")\n\n# ---- 4. Prepare for QAT ----\ntq.prepare_qat(mb_struct_pruned, inplace=True)\n\nprint(\"✅ Quantization-ready MobileNetV2 (qmobilenet_v2 NOT required)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T03:57:06.709186Z","iopub.execute_input":"2025-12-18T03:57:06.709384Z","iopub.status.idle":"2025-12-18T03:57:15.173951Z","shell.execute_reply.started":"2025-12-18T03:57:06.709364Z","shell.execute_reply":"2025-12-18T03:57:15.172953Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/3858625156.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmb_struct_pruned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_pruning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmb_struct_pruned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# ---- 2. Fuse Conv + BN + ReLU (REQUIRED for quantization) ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'mb_struct_pruned' is not defined"],"ename":"NameError","evalue":"name 'mb_struct_pruned' is not defined","output_type":"error"}],"execution_count":1},{"id":"f628c664-806a-475d-835d-90087d6d4def","cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.utils.prune as prune\nimport torch.ao.quantization as tq\nimport torchvision\nfrom torchvision.models import mobilenet_v2\n\n# ---- 1. Remove pruning reparameterization ----\ndef remove_pruning(model):\n    for m in model.modules():\n        if isinstance(m, (nn.Conv2d, nn.Linear)):\n            if hasattr(m, \"weight_orig\"):\n                prune.remove(m, \"weight\")\n    return model\n\nmb_pruned = remove_pruning(mb_struct_pruned).cpu().eval()\n\n# ---- 2. Fuse MobileNetV2 modules (required for quantization) ----\ndef fuse_mobilenet(model):\n    for m in model.modules():\n        if isinstance(m, torchvision.models.mobilenetv2.InvertedResidual):\n            if m.use_res_connect:\n                tq.fuse_modules(m.conv, [\"0\", \"1\"], inplace=True)\n            else:\n                tq.fuse_modules(m.conv, [\"0\", \"1\"], inplace=True)\n                tq.fuse_modules(m.conv, [\"3\", \"4\"], inplace=True)\n    return model\n\nmb_pruned = fuse_mobilenet(mb_pruned)\n\n# ---- 3. Assign QAT configuration ----\nmb_pruned.qconfig = tq.get_default_qat_qconfig(\"fbgemm\")\n\n# ---- 4. Prepare for Quantization-Aware Training ----\ntq.prepare_qat(mb_pruned, inplace=True)\n\nprint(\"✅ Quantization-ready MobileNetV2 (no qmobilenet_v2 needed)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T18:35:03.440863Z","iopub.execute_input":"2025-12-17T18:35:03.441765Z","iopub.status.idle":"2025-12-17T18:35:03.463058Z","shell.execute_reply.started":"2025-12-17T18:35:03.441732Z","shell.execute_reply":"2025-12-17T18:35:03.461937Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/3928167732.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mmb_pruned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuse_mobilenet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmb_pruned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# ---- 3. Assign QAT configuration ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_55/3928167732.py\u001b[0m in \u001b[0;36mfuse_mobilenet\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mtq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuse_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mtq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuse_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0mtq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuse_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"4\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/ao/quantization/fuse_modules.py\u001b[0m in \u001b[0;36mfuse_modules\u001b[0;34m(model, modules_to_fuse, inplace, fuser_func, fuse_custom_config_dict)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \"\"\"\n\u001b[0;32m--> 191\u001b[0;31m     return _fuse_modules(\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mmodules_to_fuse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/ao/quantization/fuse_modules.py\u001b[0m in \u001b[0;36m_fuse_modules\u001b[0;34m(model, modules_to_fuse, is_qat, inplace, fuser_func, fuse_custom_config_dict)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_element\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodule_element\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules_to_fuse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# Handle case of modules_to_fuse being a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         _fuse_modules_helper(\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules_to_fuse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_qat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuser_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuse_custom_config_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/ao/quantization/fuse_modules.py\u001b[0m in \u001b[0;36m_fuse_modules_helper\u001b[0;34m(model, modules_to_fuse, is_qat, fuser_func, fuse_custom_config_dict)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# Fuse list of modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mnew_mod_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuser_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_qat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_fuser_method_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;31m# Replace original module list with fused module list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/ao/quantization/fuse_modules.py\u001b[0m in \u001b[0;36mfuse_known_modules\u001b[0;34m(mod_list, is_qat, additional_fuser_method_mapping)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \"\"\"\n\u001b[1;32m     58\u001b[0m     \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_before_parametrizations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmod_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mfuser_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_fuser_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_fuser_method_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfuser_method\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Cannot fuse modules: {types}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/ao/quantization/fuser_method_mappings.py\u001b[0m in \u001b[0;36mget_fuser_method\u001b[0;34m(op_list, additional_fuser_method_mapping)\u001b[0m\n\u001b[1;32m    224\u001b[0m     )\n\u001b[1;32m    225\u001b[0m     \u001b[0mfuser_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_mappings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mfuser_method\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"did not find fuser method for: {op_list} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfuser_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: did not find fuser method for: (<class 'torchvision.ops.misc.Conv2dNormActivation'>, <class 'torch.nn.modules.conv.Conv2d'>) "],"ename":"AssertionError","evalue":"did not find fuser method for: (<class 'torchvision.ops.misc.Conv2dNormActivation'>, <class 'torch.nn.modules.conv.Conv2d'>) ","output_type":"error"}],"execution_count":16},{"id":"8782b20f-a27f-4927-812c-ab86e99a3b52","cell_type":"code","source":"import torch.ao.quantization as tq\n\ndef build_quantready_mobilenet(num_classes=10, width_mult=1.0, from_float_model=None):\n    q = qmobilenet_v2(weights=None, quantize=False, width_mult=width_mult)  # float, quant-ready\n    q.classifier[1] = nn.Linear(q.last_channel, num_classes)\n    if from_float_model is not None:\n        q.load_state_dict(from_float_model.state_dict(), strict=False)\n    return q\n\n# Best practice: quantize the pruned+finetuned model\nmb_qready = build_quantready_mobilenet(NUM_CLASSES, width_mult=1.0, from_float_model=mb_struct_pruned.to(\"cpu\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T18:07:28.281018Z","iopub.execute_input":"2025-12-17T18:07:28.281809Z","iopub.status.idle":"2025-12-17T18:07:28.393847Z","shell.execute_reply.started":"2025-12-17T18:07:28.281769Z","shell.execute_reply":"2025-12-17T18:07:28.391938Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/1971514586.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Best practice: quantize the pruned+finetuned model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmb_qready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_quantready_mobilenet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth_mult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_float_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmb_struct_pruned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_55/1971514586.py\u001b[0m in \u001b[0;36mbuild_quantready_mobilenet\u001b[0;34m(num_classes, width_mult, from_float_model)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_channel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfrom_float_model\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_float_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2623\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2624\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2625\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2626\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for QuantizableMobileNetV2:\n\tsize mismatch for features.0.0.weight: copying a param with shape torch.Size([22, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 3, 3, 3]).\n\tsize mismatch for features.0.1.weight: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.0.1.bias: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.0.1.running_mean: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.0.1.running_var: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.1.conv.0.0.weight: copying a param with shape torch.Size([22, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 1, 3, 3]).\n\tsize mismatch for features.1.conv.0.1.weight: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.1.conv.0.1.bias: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.1.conv.0.1.running_mean: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.1.conv.0.1.running_var: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.1.conv.1.weight: copying a param with shape torch.Size([11, 22, 1, 1]) from checkpoint, the shape in current model is torch.Size([16, 32, 1, 1]).\n\tsize mismatch for features.1.conv.2.weight: copying a param with shape torch.Size([11]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for features.1.conv.2.bias: copying a param with shape torch.Size([11]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for features.1.conv.2.running_mean: copying a param with shape torch.Size([11]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for features.1.conv.2.running_var: copying a param with shape torch.Size([11]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for features.2.conv.0.0.weight: copying a param with shape torch.Size([67, 11, 1, 1]) from checkpoint, the shape in current model is torch.Size([96, 16, 1, 1]).\n\tsize mismatch for features.2.conv.0.1.weight: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.2.conv.0.1.bias: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.2.conv.0.1.running_mean: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.2.conv.0.1.running_var: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.2.conv.1.0.weight: copying a param with shape torch.Size([67, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([96, 1, 3, 3]).\n\tsize mismatch for features.2.conv.1.1.weight: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.2.conv.1.1.bias: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.2.conv.1.1.running_mean: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.2.conv.1.1.running_var: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.2.conv.2.weight: copying a param with shape torch.Size([16, 67, 1, 1]) from checkpoint, the shape in current model is torch.Size([24, 96, 1, 1]).\n\tsize mismatch for features.2.conv.3.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for features.2.conv.3.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for features.2.conv.3.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for features.2.conv.3.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for features.3.conv.0.0.weight: copying a param with shape torch.Size([100, 16, 1, 1]) from checkpoint, the shape in current model is torch.Size([144, 24, 1, 1]).\n\tsize mismatch for features.3.conv.0.1.weight: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.3.conv.0.1.bias: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.3.conv.0.1.running_mean: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.3.conv.0.1.running_var: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.3.conv.1.0.weight: copying a param with shape torch.Size([100, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([144, 1, 3, 3]).\n\tsize mismatch for features.3.conv.1.1.weight: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.3.conv.1.1.bias: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.3.conv.1.1.running_mean: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.3.conv.1.1.running_var: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.3.conv.2.weight: copying a param with shape torch.Size([16, 100, 1, 1]) from checkpoint, the shape in current model is torch.Size([24, 144, 1, 1]).\n\tsize mismatch for features.3.conv.3.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for features.3.conv.3.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for features.3.conv.3.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for features.3.conv.3.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for features.4.conv.0.0.weight: copying a param with shape torch.Size([100, 16, 1, 1]) from checkpoint, the shape in current model is torch.Size([144, 24, 1, 1]).\n\tsize mismatch for features.4.conv.0.1.weight: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.4.conv.0.1.bias: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.4.conv.0.1.running_mean: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.4.conv.0.1.running_var: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.4.conv.1.0.weight: copying a param with shape torch.Size([100, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([144, 1, 3, 3]).\n\tsize mismatch for features.4.conv.1.1.weight: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.4.conv.1.1.bias: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.4.conv.1.1.running_mean: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.4.conv.1.1.running_var: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.4.conv.2.weight: copying a param with shape torch.Size([22, 100, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 144, 1, 1]).\n\tsize mismatch for features.4.conv.3.weight: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.4.conv.3.bias: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.4.conv.3.running_mean: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.4.conv.3.running_var: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.5.conv.0.0.weight: copying a param with shape torch.Size([134, 22, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 32, 1, 1]).\n\tsize mismatch for features.5.conv.0.1.weight: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.5.conv.0.1.bias: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.5.conv.0.1.running_mean: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.5.conv.0.1.running_var: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.5.conv.1.0.weight: copying a param with shape torch.Size([134, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([192, 1, 3, 3]).\n\tsize mismatch for features.5.conv.1.1.weight: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.5.conv.1.1.bias: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.5.conv.1.1.running_mean: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.5.conv.1.1.running_var: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.5.conv.2.weight: copying a param with shape torch.Size([22, 134, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 192, 1, 1]).\n\tsize mismatch for features.5.conv.3.weight: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.5.conv.3.bias: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.5.conv.3.running_mean: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.5.conv.3.running_var: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.6.conv.0.0.weight: copying a param with shape torch.Size([134, 22, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 32, 1, 1]).\n\tsize mismatch for features.6.conv.0.1.weight: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.6.conv.0.1.bias: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.6.conv.0.1.running_mean: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.6.conv.0.1.running_var: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.6.conv.1.0.weight: copying a param with shape torch.Size([134, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([192, 1, 3, 3]).\n\tsize mismatch for features.6.conv.1.1.weight: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.6.conv.1.1.bias: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.6.conv.1.1.running_mean: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.6.conv.1.1.running_var: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.6.conv.2.weight: copying a param with shape torch.Size([22, 134, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 192, 1, 1]).\n\tsize mismatch for features.6.conv.3.weight: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.6.conv.3.bias: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.6.conv.3.running_mean: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.6.conv.3.running_var: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.7.conv.0.0.weight: copying a param with shape torch.Size([134, 22, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 32, 1, 1]).\n\tsize mismatch for features.7.conv.0.1.weight: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.7.conv.0.1.bias: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.7.conv.0.1.running_mean: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.7.conv.0.1.running_var: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.7.conv.1.0.weight: copying a param with shape torch.Size([134, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([192, 1, 3, 3]).\n\tsize mismatch for features.7.conv.1.1.weight: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.7.conv.1.1.bias: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.7.conv.1.1.running_mean: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.7.conv.1.1.running_var: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.7.conv.2.weight: copying a param with shape torch.Size([44, 134, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 192, 1, 1]).\n\tsize mismatch for features.7.conv.3.weight: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.7.conv.3.bias: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.7.conv.3.running_mean: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.7.conv.3.running_var: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.8.conv.0.0.weight: copying a param with shape torch.Size([268, 44, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 64, 1, 1]).\n\tsize mismatch for features.8.conv.0.1.weight: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.8.conv.0.1.bias: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.8.conv.0.1.running_mean: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.8.conv.0.1.running_var: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.8.conv.1.0.weight: copying a param with shape torch.Size([268, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([384, 1, 3, 3]).\n\tsize mismatch for features.8.conv.1.1.weight: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.8.conv.1.1.bias: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.8.conv.1.1.running_mean: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.8.conv.1.1.running_var: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.8.conv.2.weight: copying a param with shape torch.Size([44, 268, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 384, 1, 1]).\n\tsize mismatch for features.8.conv.3.weight: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.8.conv.3.bias: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.8.conv.3.running_mean: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.8.conv.3.running_var: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.9.conv.0.0.weight: copying a param with shape torch.Size([268, 44, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 64, 1, 1]).\n\tsize mismatch for features.9.conv.0.1.weight: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.9.conv.0.1.bias: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.9.conv.0.1.running_mean: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.9.conv.0.1.running_var: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.9.conv.1.0.weight: copying a param with shape torch.Size([268, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([384, 1, 3, 3]).\n\tsize mismatch for features.9.conv.1.1.weight: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.9.conv.1.1.bias: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.9.conv.1.1.running_mean: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.9.conv.1.1.running_var: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.9.conv.2.weight: copying a param with shape torch.Size([44, 268, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 384, 1, 1]).\n\tsize mismatch for features.9.conv.3.weight: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.9.conv.3.bias: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.9.conv.3.running_mean: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.9.conv.3.running_var: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.10.conv.0.0.weight: copying a param with shape torch.Size([268, 44, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 64, 1, 1]).\n\tsize mismatch for features.10.conv.0.1.weight: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.10.conv.0.1.bias: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.10.conv.0.1.running_mean: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.10.conv.0.1.running_var: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.10.conv.1.0.weight: copying a param with shape torch.Size([268, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([384, 1, 3, 3]).\n\tsize mismatch for features.10.conv.1.1.weight: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.10.conv.1.1.bias: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.10.conv.1.1.running_mean: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.10.conv.1.1.running_var: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.10.conv.2.weight: copying a param with shape torch.Size([44, 268, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 384, 1, 1]).\n\tsize mismatch for features.10.conv.3.weight: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.10.conv.3.bias: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.10.conv.3.running_mean: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.10.conv.3.running_var: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.11.conv.0.0.weight: copying a param with shape torch.Size([268, 44, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 64, 1, 1]).\n\tsize mismatch for features.11.conv.0.1.weight: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.11.conv.0.1.bias: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.11.conv.0.1.running_mean: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.11.conv.0.1.running_var: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.11.conv.1.0.weight: copying a param with shape torch.Size([268, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([384, 1, 3, 3]).\n\tsize mismatch for features.11.conv.1.1.weight: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.11.conv.1.1.bias: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.11.conv.1.1.running_mean: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.11.conv.1.1.running_var: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.11.conv.2.weight: copying a param with shape torch.Size([67, 268, 1, 1]) from checkpoint, the shape in current model is torch.Size([96, 384, 1, 1]).\n\tsize mismatch for features.11.conv.3.weight: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.11.conv.3.bias: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.11.conv.3.running_mean: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.11.conv.3.running_var: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.12.conv.0.0.weight: copying a param with shape torch.Size([403, 67, 1, 1]) from checkpoint, the shape in current model is torch.Size([576, 96, 1, 1]).\n\tsize mismatch for features.12.conv.0.1.weight: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.12.conv.0.1.bias: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.12.conv.0.1.running_mean: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.12.conv.0.1.running_var: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.12.conv.1.0.weight: copying a param with shape torch.Size([403, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([576, 1, 3, 3]).\n\tsize mismatch for features.12.conv.1.1.weight: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.12.conv.1.1.bias: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.12.conv.1.1.running_mean: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.12.conv.1.1.running_var: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.12.conv.2.weight: copying a param with shape torch.Size([67, 403, 1, 1]) from checkpoint, the shape in current model is torch.Size([96, 576, 1, 1]).\n\tsize mismatch for features.12.conv.3.weight: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.12.conv.3.bias: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.12.conv.3.running_mean: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.12.conv.3.running_var: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.13.conv.0.0.weight: copying a param with shape torch.Size([403, 67, 1, 1]) from checkpoint, the shape in current model is torch.Size([576, 96, 1, 1]).\n\tsize mismatch for features.13.conv.0.1.weight: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.13.conv.0.1.bias: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.13.conv.0.1.running_mean: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.13.conv.0.1.running_var: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.13.conv.1.0.weight: copying a param with shape torch.Size([403, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([576, 1, 3, 3]).\n\tsize mismatch for features.13.conv.1.1.weight: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.13.conv.1.1.bias: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.13.conv.1.1.running_mean: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.13.conv.1.1.running_var: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.13.conv.2.weight: copying a param with shape torch.Size([67, 403, 1, 1]) from checkpoint, the shape in current model is torch.Size([96, 576, 1, 1]).\n\tsize mismatch for features.13.conv.3.weight: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.13.conv.3.bias: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.13.conv.3.running_mean: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.13.conv.3.running_var: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.14.conv.0.0.weight: copying a param with shape torch.Size([403, 67, 1, 1]) from checkpoint, the shape in current model is torch.Size([576, 96, 1, 1]).\n\tsize mismatch for features.14.conv.0.1.weight: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.14.conv.0.1.bias: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.14.conv.0.1.running_mean: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.14.conv.0.1.running_var: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.14.conv.1.0.weight: copying a param with shape torch.Size([403, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([576, 1, 3, 3]).\n\tsize mismatch for features.14.conv.1.1.weight: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.14.conv.1.1.bias: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.14.conv.1.1.running_mean: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.14.conv.1.1.running_var: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.14.conv.2.weight: copying a param with shape torch.Size([112, 403, 1, 1]) from checkpoint, the shape in current model is torch.Size([160, 576, 1, 1]).\n\tsize mismatch for features.14.conv.3.weight: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([160]).\n\tsize mismatch for features.14.conv.3.bias: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([160]).\n\tsize mismatch for features.14.conv.3.running_mean: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([160]).\n\tsize mismatch for features.14.conv.3.running_var: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([160]).\n\tsize mismatch for features.15.conv.0.0.weight: copying a param with shape torch.Size([672, 112, 1, 1]) from checkpoint, the shape in current model is torch.Size([960, 160, 1, 1]).\n\tsize mismatch for features.15.conv.0.1.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.15.conv.0.1.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.15.conv.0.1.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.15.conv.0.1.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.15.conv.1.0.weight: copying a param with shape torch.Size([672, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([960, 1, 3, 3]).\n\tsize mismatch for features.15.conv.1.1.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.15.conv.1.1.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.15.conv.1.1.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.15.conv.1.1.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.15.conv.2.weight: copying a param with shape torch.Size([112, 672, 1, 1]) from checkpoint, the shape in current model is torch.Size([160, 960, 1, 1]).\n\tsize mismatch for features.15.conv.3.weight: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([160]).\n\tsize mismatch for features.15.conv.3.bias: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([160]).\n\tsize mismatch for features.15.conv.3.running_mean: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([160]).\n\tsize mismatch for features.15.conv.3.running_var: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([160]).\n\tsize mismatch for features.16.conv.0.0.weight: copying a param with shape torch.Size([672, 112, 1, 1]) from checkpoint, the shape in current model is torch.Size([960, 160, 1, 1]).\n\tsize mismatch for features.16.conv.0.1.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.16.conv.0.1.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.16.conv.0.1.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.16.conv.0.1.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.16.conv.1.0.weight: copying a param with shape torch.Size([672, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([960, 1, 3, 3]).\n\tsize mismatch for features.16.conv.1.1.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.16.conv.1.1.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.16.conv.1.1.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.16.conv.1.1.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.16.conv.2.weight: copying a param with shape torch.Size([112, 672, 1, 1]) from checkpoint, the shape in current model is torch.Size([160, 960, 1, 1]).\n\tsize mismatch for features.16.conv.3.weight: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([160]).\n\tsize mismatch for features.16.conv.3.bias: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([160]).\n\tsize mismatch for features.16.conv.3.running_mean: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([160]).\n\tsize mismatch for features.16.conv.3.running_var: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([160]).\n\tsize mismatch for features.17.conv.0.0.weight: copying a param with shape torch.Size([672, 112, 1, 1]) from checkpoint, the shape in current model is torch.Size([960, 160, 1, 1]).\n\tsize mismatch for features.17.conv.0.1.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.17.conv.0.1.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.17.conv.0.1.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.17.conv.0.1.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.17.conv.1.0.weight: copying a param with shape torch.Size([672, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([960, 1, 3, 3]).\n\tsize mismatch for features.17.conv.1.1.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.17.conv.1.1.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.17.conv.1.1.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.17.conv.1.1.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.17.conv.2.weight: copying a param with shape torch.Size([224, 672, 1, 1]) from checkpoint, the shape in current model is torch.Size([320, 960, 1, 1]).\n\tsize mismatch for features.17.conv.3.weight: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for features.17.conv.3.bias: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for features.17.conv.3.running_mean: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for features.17.conv.3.running_var: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for features.18.0.weight: copying a param with shape torch.Size([896, 224, 1, 1]) from checkpoint, the shape in current model is torch.Size([1280, 320, 1, 1]).\n\tsize mismatch for features.18.1.weight: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([1280]).\n\tsize mismatch for features.18.1.bias: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([1280]).\n\tsize mismatch for features.18.1.running_mean: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([1280]).\n\tsize mismatch for features.18.1.running_var: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([1280]).\n\tsize mismatch for classifier.1.weight: copying a param with shape torch.Size([10, 896]) from checkpoint, the shape in current model is torch.Size([10, 1280])."],"ename":"RuntimeError","evalue":"Error(s) in loading state_dict for QuantizableMobileNetV2:\n\tsize mismatch for features.0.0.weight: copying a param with shape torch.Size([22, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 3, 3, 3]).\n\tsize mismatch for features.0.1.weight: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.0.1.bias: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.0.1.running_mean: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.0.1.running_var: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.1.conv.0.0.weight: copying a param with shape torch.Size([22, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 1, 3, 3]).\n\tsize mismatch for features.1.conv.0.1.weight: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.1.conv.0.1.bias: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.1.conv.0.1.running_mean: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.1.conv.0.1.running_var: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.1.conv.1.weight: copying a param with shape torch.Size([11, 22, 1, 1]) from checkpoint, the shape in current model is torch.Size([16, 32, 1, 1]).\n\tsize mismatch for features.1.conv.2.weight: copying a param with shape torch.Size([11]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for features.1.conv.2.bias: copying a param with shape torch.Size([11]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for features.1.conv.2.running_mean: copying a param with shape torch.Size([11]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for features.1.conv.2.running_var: copying a param with shape torch.Size([11]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for features.2.conv.0.0.weight: copying a param with shape torch.Size([67, 11, 1, 1]) from checkpoint, the shape in current model is torch.Size([96, 16, 1, 1]).\n\tsize mismatch for features.2.conv.0.1.weight: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.2.conv.0.1.bias: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.2.conv.0.1.running_mean: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.2.conv.0.1.running_var: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.2.conv.1.0.weight: copying a param with shape torch.Size([67, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([96, 1, 3, 3]).\n\tsize mismatch for features.2.conv.1.1.weight: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.2.conv.1.1.bias: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.2.conv.1.1.running_mean: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.2.conv.1.1.running_var: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.2.conv.2.weight: copying a param with shape torch.Size([16, 67, 1, 1]) from checkpoint, the shape in current model is torch.Size([24, 96, 1, 1]).\n\tsize mismatch for features.2.conv.3.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for features.2.conv.3.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for features.2.conv.3.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for features.2.conv.3.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for features.3.conv.0.0.weight: copying a param with shape torch.Size([100, 16, 1, 1]) from checkpoint, the shape in current model is torch.Size([144, 24, 1, 1]).\n\tsize mismatch for features.3.conv.0.1.weight: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.3.conv.0.1.bias: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.3.conv.0.1.running_mean: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.3.conv.0.1.running_var: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.3.conv.1.0.weight: copying a param with shape torch.Size([100, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([144, 1, 3, 3]).\n\tsize mismatch for features.3.conv.1.1.weight: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.3.conv.1.1.bias: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.3.conv.1.1.running_mean: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.3.conv.1.1.running_var: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.3.conv.2.weight: copying a param with shape torch.Size([16, 100, 1, 1]) from checkpoint, the shape in current model is torch.Size([24, 144, 1, 1]).\n\tsize mismatch for features.3.conv.3.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for features.3.conv.3.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for features.3.conv.3.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for features.3.conv.3.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for features.4.conv.0.0.weight: copying a param with shape torch.Size([100, 16, 1, 1]) from checkpoint, the shape in current model is torch.Size([144, 24, 1, 1]).\n\tsize mismatch for features.4.conv.0.1.weight: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.4.conv.0.1.bias: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.4.conv.0.1.running_mean: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.4.conv.0.1.running_var: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.4.conv.1.0.weight: copying a param with shape torch.Size([100, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([144, 1, 3, 3]).\n\tsize mismatch for features.4.conv.1.1.weight: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.4.conv.1.1.bias: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.4.conv.1.1.running_mean: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.4.conv.1.1.running_var: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for features.4.conv.2.weight: copying a param with shape torch.Size([22, 100, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 144, 1, 1]).\n\tsize mismatch for features.4.conv.3.weight: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.4.conv.3.bias: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.4.conv.3.running_mean: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.4.conv.3.running_var: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.5.conv.0.0.weight: copying a param with shape torch.Size([134, 22, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 32, 1, 1]).\n\tsize mismatch for features.5.conv.0.1.weight: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.5.conv.0.1.bias: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.5.conv.0.1.running_mean: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.5.conv.0.1.running_var: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.5.conv.1.0.weight: copying a param with shape torch.Size([134, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([192, 1, 3, 3]).\n\tsize mismatch for features.5.conv.1.1.weight: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.5.conv.1.1.bias: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.5.conv.1.1.running_mean: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.5.conv.1.1.running_var: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.5.conv.2.weight: copying a param with shape torch.Size([22, 134, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 192, 1, 1]).\n\tsize mismatch for features.5.conv.3.weight: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.5.conv.3.bias: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.5.conv.3.running_mean: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.5.conv.3.running_var: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.6.conv.0.0.weight: copying a param with shape torch.Size([134, 22, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 32, 1, 1]).\n\tsize mismatch for features.6.conv.0.1.weight: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.6.conv.0.1.bias: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.6.conv.0.1.running_mean: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.6.conv.0.1.running_var: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.6.conv.1.0.weight: copying a param with shape torch.Size([134, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([192, 1, 3, 3]).\n\tsize mismatch for features.6.conv.1.1.weight: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.6.conv.1.1.bias: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.6.conv.1.1.running_mean: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.6.conv.1.1.running_var: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.6.conv.2.weight: copying a param with shape torch.Size([22, 134, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 192, 1, 1]).\n\tsize mismatch for features.6.conv.3.weight: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.6.conv.3.bias: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.6.conv.3.running_mean: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.6.conv.3.running_var: copying a param with shape torch.Size([22]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for features.7.conv.0.0.weight: copying a param with shape torch.Size([134, 22, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 32, 1, 1]).\n\tsize mismatch for features.7.conv.0.1.weight: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.7.conv.0.1.bias: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.7.conv.0.1.running_mean: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.7.conv.0.1.running_var: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.7.conv.1.0.weight: copying a param with shape torch.Size([134, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([192, 1, 3, 3]).\n\tsize mismatch for features.7.conv.1.1.weight: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.7.conv.1.1.bias: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.7.conv.1.1.running_mean: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.7.conv.1.1.running_var: copying a param with shape torch.Size([134]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for features.7.conv.2.weight: copying a param with shape torch.Size([44, 134, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 192, 1, 1]).\n\tsize mismatch for features.7.conv.3.weight: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.7.conv.3.bias: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.7.conv.3.running_mean: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.7.conv.3.running_var: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.8.conv.0.0.weight: copying a param with shape torch.Size([268, 44, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 64, 1, 1]).\n\tsize mismatch for features.8.conv.0.1.weight: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.8.conv.0.1.bias: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.8.conv.0.1.running_mean: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.8.conv.0.1.running_var: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.8.conv.1.0.weight: copying a param with shape torch.Size([268, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([384, 1, 3, 3]).\n\tsize mismatch for features.8.conv.1.1.weight: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.8.conv.1.1.bias: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.8.conv.1.1.running_mean: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.8.conv.1.1.running_var: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.8.conv.2.weight: copying a param with shape torch.Size([44, 268, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 384, 1, 1]).\n\tsize mismatch for features.8.conv.3.weight: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.8.conv.3.bias: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.8.conv.3.running_mean: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.8.conv.3.running_var: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.9.conv.0.0.weight: copying a param with shape torch.Size([268, 44, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 64, 1, 1]).\n\tsize mismatch for features.9.conv.0.1.weight: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.9.conv.0.1.bias: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.9.conv.0.1.running_mean: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.9.conv.0.1.running_var: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.9.conv.1.0.weight: copying a param with shape torch.Size([268, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([384, 1, 3, 3]).\n\tsize mismatch for features.9.conv.1.1.weight: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.9.conv.1.1.bias: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.9.conv.1.1.running_mean: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.9.conv.1.1.running_var: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.9.conv.2.weight: copying a param with shape torch.Size([44, 268, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 384, 1, 1]).\n\tsize mismatch for features.9.conv.3.weight: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.9.conv.3.bias: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.9.conv.3.running_mean: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.9.conv.3.running_var: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.10.conv.0.0.weight: copying a param with shape torch.Size([268, 44, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 64, 1, 1]).\n\tsize mismatch for features.10.conv.0.1.weight: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.10.conv.0.1.bias: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.10.conv.0.1.running_mean: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.10.conv.0.1.running_var: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.10.conv.1.0.weight: copying a param with shape torch.Size([268, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([384, 1, 3, 3]).\n\tsize mismatch for features.10.conv.1.1.weight: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.10.conv.1.1.bias: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.10.conv.1.1.running_mean: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.10.conv.1.1.running_var: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.10.conv.2.weight: copying a param with shape torch.Size([44, 268, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 384, 1, 1]).\n\tsize mismatch for features.10.conv.3.weight: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.10.conv.3.bias: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.10.conv.3.running_mean: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.10.conv.3.running_var: copying a param with shape torch.Size([44]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for features.11.conv.0.0.weight: copying a param with shape torch.Size([268, 44, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 64, 1, 1]).\n\tsize mismatch for features.11.conv.0.1.weight: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.11.conv.0.1.bias: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.11.conv.0.1.running_mean: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.11.conv.0.1.running_var: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.11.conv.1.0.weight: copying a param with shape torch.Size([268, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([384, 1, 3, 3]).\n\tsize mismatch for features.11.conv.1.1.weight: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.11.conv.1.1.bias: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.11.conv.1.1.running_mean: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.11.conv.1.1.running_var: copying a param with shape torch.Size([268]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for features.11.conv.2.weight: copying a param with shape torch.Size([67, 268, 1, 1]) from checkpoint, the shape in current model is torch.Size([96, 384, 1, 1]).\n\tsize mismatch for features.11.conv.3.weight: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.11.conv.3.bias: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.11.conv.3.running_mean: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.11.conv.3.running_var: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.12.conv.0.0.weight: copying a param with shape torch.Size([403, 67, 1, 1]) from checkpoint, the shape in current model is torch.Size([576, 96, 1, 1]).\n\tsize mismatch for features.12.conv.0.1.weight: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.12.conv.0.1.bias: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.12.conv.0.1.running_mean: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.12.conv.0.1.running_var: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.12.conv.1.0.weight: copying a param with shape torch.Size([403, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([576, 1, 3, 3]).\n\tsize mismatch for features.12.conv.1.1.weight: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.12.conv.1.1.bias: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.12.conv.1.1.running_mean: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.12.conv.1.1.running_var: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.12.conv.2.weight: copying a param with shape torch.Size([67, 403, 1, 1]) from checkpoint, the shape in current model is torch.Size([96, 576, 1, 1]).\n\tsize mismatch for features.12.conv.3.weight: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.12.conv.3.bias: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.12.conv.3.running_mean: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.12.conv.3.running_var: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.13.conv.0.0.weight: copying a param with shape torch.Size([403, 67, 1, 1]) from checkpoint, the shape in current model is torch.Size([576, 96, 1, 1]).\n\tsize mismatch for features.13.conv.0.1.weight: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.13.conv.0.1.bias: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.13.conv.0.1.running_mean: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.13.conv.0.1.running_var: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.13.conv.1.0.weight: copying a param with shape torch.Size([403, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([576, 1, 3, 3]).\n\tsize mismatch for features.13.conv.1.1.weight: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.13.conv.1.1.bias: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.13.conv.1.1.running_mean: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.13.conv.1.1.running_var: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.13.conv.2.weight: copying a param with shape torch.Size([67, 403, 1, 1]) from checkpoint, the shape in current model is torch.Size([96, 576, 1, 1]).\n\tsize mismatch for features.13.conv.3.weight: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.13.conv.3.bias: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.13.conv.3.running_mean: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.13.conv.3.running_var: copying a param with shape torch.Size([67]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for features.14.conv.0.0.weight: copying a param with shape torch.Size([403, 67, 1, 1]) from checkpoint, the shape in current model is torch.Size([576, 96, 1, 1]).\n\tsize mismatch for features.14.conv.0.1.weight: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.14.conv.0.1.bias: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.14.conv.0.1.running_mean: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.14.conv.0.1.running_var: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.14.conv.1.0.weight: copying a param with shape torch.Size([403, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([576, 1, 3, 3]).\n\tsize mismatch for features.14.conv.1.1.weight: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.14.conv.1.1.bias: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.14.conv.1.1.running_mean: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.14.conv.1.1.running_var: copying a param with shape torch.Size([403]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for features.14.conv.2.weight: copying a param with shape torch.Size([112, 403, 1, 1]) from checkpoint, the shape in current model is torch.Size([160, 576, 1, 1]).\n\tsize mismatch for features.14.conv.3.weight: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([160]).\n\tsize mismatch for features.14.conv.3.bias: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([160]).\n\tsize mismatch for features.14.conv.3.running_mean: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([160]).\n\tsize mismatch for features.14.conv.3.running_var: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([160]).\n\tsize mismatch for features.15.conv.0.0.weight: copying a param with shape torch.Size([672, 112, 1, 1]) from checkpoint, the shape in current model is torch.Size([960, 160, 1, 1]).\n\tsize mismatch for features.15.conv.0.1.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.15.conv.0.1.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.15.conv.0.1.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.15.conv.0.1.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.15.conv.1.0.weight: copying a param with shape torch.Size([672, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([960, 1, 3, 3]).\n\tsize mismatch for features.15.conv.1.1.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.15.conv.1.1.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.15.conv.1.1.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.15.conv.1.1.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.15.conv.2.weight: copying a param with shape torch.Size([112, 672, 1, 1]) from checkpoint, the shape in current model is torch.Size([160, 960, 1, 1]).\n\tsize mismatch for features.15.conv.3.weight: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([160]).\n\tsize mismatch for features.15.conv.3.bias: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([160]).\n\tsize mismatch for features.15.conv.3.running_mean: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([160]).\n\tsize mismatch for features.15.conv.3.running_var: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([160]).\n\tsize mismatch for features.16.conv.0.0.weight: copying a param with shape torch.Size([672, 112, 1, 1]) from checkpoint, the shape in current model is torch.Size([960, 160, 1, 1]).\n\tsize mismatch for features.16.conv.0.1.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.16.conv.0.1.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.16.conv.0.1.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.16.conv.0.1.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.16.conv.1.0.weight: copying a param with shape torch.Size([672, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([960, 1, 3, 3]).\n\tsize mismatch for features.16.conv.1.1.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.16.conv.1.1.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.16.conv.1.1.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.16.conv.1.1.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.16.conv.2.weight: copying a param with shape torch.Size([112, 672, 1, 1]) from checkpoint, the shape in current model is torch.Size([160, 960, 1, 1]).\n\tsize mismatch for features.16.conv.3.weight: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([160]).\n\tsize mismatch for features.16.conv.3.bias: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([160]).\n\tsize mismatch for features.16.conv.3.running_mean: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([160]).\n\tsize mismatch for features.16.conv.3.running_var: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([160]).\n\tsize mismatch for features.17.conv.0.0.weight: copying a param with shape torch.Size([672, 112, 1, 1]) from checkpoint, the shape in current model is torch.Size([960, 160, 1, 1]).\n\tsize mismatch for features.17.conv.0.1.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.17.conv.0.1.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.17.conv.0.1.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.17.conv.0.1.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.17.conv.1.0.weight: copying a param with shape torch.Size([672, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([960, 1, 3, 3]).\n\tsize mismatch for features.17.conv.1.1.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.17.conv.1.1.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.17.conv.1.1.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.17.conv.1.1.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([960]).\n\tsize mismatch for features.17.conv.2.weight: copying a param with shape torch.Size([224, 672, 1, 1]) from checkpoint, the shape in current model is torch.Size([320, 960, 1, 1]).\n\tsize mismatch for features.17.conv.3.weight: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for features.17.conv.3.bias: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for features.17.conv.3.running_mean: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for features.17.conv.3.running_var: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for features.18.0.weight: copying a param with shape torch.Size([896, 224, 1, 1]) from checkpoint, the shape in current model is torch.Size([1280, 320, 1, 1]).\n\tsize mismatch for features.18.1.weight: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([1280]).\n\tsize mismatch for features.18.1.bias: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([1280]).\n\tsize mismatch for features.18.1.running_mean: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([1280]).\n\tsize mismatch for features.18.1.running_var: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([1280]).\n\tsize mismatch for classifier.1.weight: copying a param with shape torch.Size([10, 896]) from checkpoint, the shape in current model is torch.Size([10, 1280]).","output_type":"error"}],"execution_count":14},{"id":"cd5c2ddd-c739-4493-821e-59814dc5bd48","cell_type":"markdown","source":"## CELL 11 — PTQ Static INT8 (CPU)\n","metadata":{}},{"id":"0f8f2992-0c2c-4bf5-a5d4-37c3f25b9be4","cell_type":"code","source":"def calibrate(model, loader, num_batches=30):\n    model.eval()\n    with torch.no_grad():\n        for i, (x, _) in enumerate(loader):\n            if i >= num_batches: break\n            model(x)\n\ndef ptq_int8(model_fp32_quantready, train_loader):\n    m = copy.deepcopy(model_fp32_quantready).cpu().eval()\n    torch.backends.quantized.engine = \"fbgemm\"\n\n    m.qconfig = tq.get_default_qconfig(\"fbgemm\")\n    m_prepared = tq.prepare(m, inplace=False)\n\n    calibrate(m_prepared, train_loader, num_batches=30)\n    m_int8 = tq.convert(m_prepared, inplace=False)\n    return m_int8\n\nmb_ptq_int8 = ptq_int8(mb_qready, train_loader)\nacc_ptq = evaluate(mb_ptq_int8, test_loader, device=\"cpu\")\nprint(\"PTQ INT8 acc (CPU):\", acc_ptq)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"47321bcc-0046-415c-bfd4-c02b24394b72","cell_type":"markdown","source":"## CELL 12 — QAT INT8 (CPU)\n","metadata":{}},{"id":"6b8b3f1c-ebf3-4e97-aba9-51b095801e02","cell_type":"code","source":"def qat_int8(model_fp32_quantready, train_loader, test_loader, epochs=2, lr=5e-5):\n    m = copy.deepcopy(model_fp32_quantready).cpu()\n    torch.backends.quantized.engine = \"fbgemm\"\n\n    m.qconfig = tq.get_default_qat_qconfig(\"fbgemm\")\n    m_prepared = tq.prepare_qat(m, inplace=False)\n\n    opt = optim.Adam(m_prepared.parameters(), lr=lr)\n    loss_fn = nn.CrossEntropyLoss()\n\n    for ep in range(1, epochs+1):\n        m_prepared.train()\n        for x, y in train_loader:\n            x, y = x.cpu(), y.cpu()\n            opt.zero_grad()\n            loss = loss_fn(m_prepared(x), y)\n            loss.backward()\n            opt.step()\n\n        m_prepared.eval()\n        acc = evaluate(m_prepared, test_loader, device=\"cpu\")\n        print(f\"QAT epoch {ep}/{epochs} | acc={acc:.4f}\")\n\n    m_int8 = tq.convert(m_prepared.eval(), inplace=False)\n    return m_int8\n\nmb_qat_int8 = qat_int8(mb_qready, train_loader, test_loader, epochs=2, lr=5e-5)\nacc_qat = evaluate(mb_qat_int8, test_loader, device=\"cpu\")\nprint(\"QAT INT8 acc (CPU):\", acc_qat)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"afefaa7f-057e-4cea-a98a-900b6776ad8f","cell_type":"markdown","source":"# PART D — Final Comparison Table\n","metadata":{}},{"id":"1a2f3369-bb35-4db7-9090-5db2962e753f","cell_type":"markdown","source":"## CELL 13 — Report (Accuracy, Params, Size, FLOPs, Latency)\n","metadata":{}},{"id":"ed9d6381-ed11-4879-ad61-71f9b01b4e41","cell_type":"code","source":"def row(name, model, device, note=\"\"):\n    model = model.to(device)\n    acc = evaluate(model, test_loader, device)\n    params = count_params(model)\n    sz = round(size_mb_fp32(model), 2) if device != \"cpu_int8\" else \"INT8\"\n    flops, _ = flops_params(model, device=(\"cpu\" if device==\"cpu\" else device))\n    lat = latency_ms(model, device=(\"cpu\" if device==\"cpu\" else device))\n    return {\n        \"model\": name,\n        \"acc\": round(acc, 4),\n        \"params\": params,\n        \"size_mb(fp32 approx)\": sz,\n        \"FLOPs\": int(flops),\n        \"lat_ms\": round(lat, 2),\n        \"note\": note\n    }\n\nrows = []\nrows.append(row(\"MobileNetV2 fp32 (width=1.0)\", mb_full, DEVICE, \"baseline\"))\nrows.append(row(\"MobileNetV2 fp32 (width=0.5)\", mb_small, DEVICE, \"parameter decrease via width_mult\"))\nrows.append(row(\"MobileNetV2 structured pruned fp32\", mb_struct_pruned, DEVICE, \"real params reduced (channel prune)\"))\nrows.append(row(\"MobileNetV2 PTQ INT8 (CPU)\", mb_ptq_int8, \"cpu\", \"post-training int8\"))\nrows.append(row(\"MobileNetV2 QAT INT8 (CPU)\", mb_qat_int8, \"cpu\", \"quantization-aware training\"))\n\ndf = pd.DataFrame(rows).sort_values(\"acc\", ascending=False)\ndf\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}